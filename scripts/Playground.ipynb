{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d45f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=False):\n",
    "        super(Resnet18, self).__init__()\n",
    "        model = resnet18(pretrained)\n",
    "\n",
    "        # take pretrained resnet, except AvgPool and FC\n",
    "        self.conv1 = model.conv1\n",
    "        self.bn1 = model.bn1\n",
    "        self.relu = model.relu\n",
    "        self.maxpool = model.maxpool\n",
    "        self.layer1 = model.layer1\n",
    "        self.layer2 = model.layer2\n",
    "        self.layer3 = model.layer3\n",
    "        self.layer4 = model.layer4\n",
    "        self.last_conv = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        x = torch.cat([x, x, x], dim=1)  # 扩充为3通道\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        low = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        high = x\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=True)\n",
    "        return x, low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88737cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class U_Net_R18(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet - Basic Implementation\n",
    "    Paper : https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=1, out_ch=4):\n",
    "        super(U_Net, self).__init__()\n",
    "        n1 = 32\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(in_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    # self.active = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "        \n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "        return out, e2, e5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32d72bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 14, 14])\n",
      "torch.Size([2, 4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "r18 = U_Net()\n",
    "x = torch.rand(2,1,224,224)\n",
    "out, e2, e5   = r18(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "067ec116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256, 512, 1024, 2048]\n"
     ]
    }
   ],
   "source": [
    "n1 = 64\n",
    "filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16, n1*32]\n",
    "print(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "94fc0922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 112, 112]) torch.Size([2, 256, 56, 56]) torch.Size([2, 512, 28, 28]) torch.Size([2, 1024, 14, 14]) torch.Size([2, 2048, 7, 7]) torch.Size([2, 1024, 14, 14]) torch.Size([2, 512, 28, 28]) torch.Size([2, 256, 56, 56]) torch.Size([2, 128, 112, 112]) torch.Size([2, 4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class U_Net_R50(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet with ResNet-50 Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=4):\n",
    "        super(U_Net_R50, self).__init__()\n",
    "        \n",
    "        # Encoder (ResNet-50)\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool\n",
    "        )\n",
    "        self.encoder2 = resnet.layer1\n",
    "        self.encoder3 = resnet.layer2\n",
    "        self.encoder4 = resnet.layer3\n",
    "        self.encoder5 = resnet.layer4\n",
    "        \n",
    "        # Decoder\n",
    "        self.Up5 = up_conv(2048, 1024)  # ResNet-50 layer4 output has 2048 channels\n",
    "        self.Up_conv5 = conv_block(2048, 1024)\n",
    "        \n",
    "        self.Up4 = up_conv(1024, 512)\n",
    "        self.Up_conv4 = conv_block(1024, 512)\n",
    "        \n",
    "        self.Up3 = up_conv(512, 256)\n",
    "        self.Up_conv3 = conv_block(512, 256)\n",
    "        \n",
    "        self.Up2 = up_conv(256, 128)\n",
    "        self.Up_conv2 = conv_block(192, 128)\n",
    "        \n",
    "        self.Up1 = up_conv(128, 64)\n",
    "        self.Up_conv1 = conv_block(67, 64)\n",
    "\n",
    "        self.Conv = nn.Conv2d(64, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        e1 = F.interpolate(e1, size=d2.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Up1(d2)\n",
    "        d1 = torch.cat((x, d1), dim=1)  # Fix the input channel dimension here\n",
    "        d1 = self.Up_conv1(d1)\n",
    "\n",
    "        out = self.Conv(d1)\n",
    "\n",
    "        return e1,e2,e3,e4,e5, d5,d4,d3,d2,out\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a U-Net with ResNet-50 encoder, 3 input channels, and 4 output channels\n",
    "model = U_Net_R50(in_ch=3, out_ch=4)\n",
    "# r18 = U_Net_ResNet18()\n",
    "x = torch.rand(2,3,224,224)\n",
    "e1,e2,e3,e4,e5, d5,d4,d3,d2,out   = model(x)\n",
    "print(e1.shape,e2.shape,e3.shape,e4.shape,e5.shape, d5.shape,d4.shape,d3.shape,d2.shape,out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1ccc8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class U_Net_ResNet18(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=4):\n",
    "        super(U_Net_ResNet18, self).__init__()\n",
    "        \n",
    "        # Encoder (ResNet-18)\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool\n",
    "        )\n",
    "        self.encoder2 = resnet.layer1\n",
    "        self.encoder3 = resnet.layer2\n",
    "        self.encoder4 = resnet.layer3\n",
    "        self.encoder5 = resnet.layer4\n",
    "        \n",
    "        # Decoder\n",
    "        self.Up5 = up_conv(512, 256)  # ResNet-18 layer4 output has 512 channels\n",
    "        self.Up_conv5 = conv_block(512, 256)\n",
    "        \n",
    "        self.Up4 = up_conv(256, 128)\n",
    "        self.Up_conv4 = conv_block(256, 128)\n",
    "        \n",
    "        self.Up3 = up_conv(128, 64)\n",
    "        self.Up_conv3 = conv_block(128, 64)\n",
    "        \n",
    "        self.Up2 = up_conv(64, 32)\n",
    "        self.Up_conv2 = conv_block(64+32, 32)\n",
    "        \n",
    "        self.Conv = nn.Conv2d(32, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def t_guided_s(self, s, t):\n",
    "        \"\"\"\n",
    "        Compact Cross-Attention from Teacher to Student feature maps.\n",
    "        \"\"\"\n",
    "#         print(s.shape)\n",
    "        s_pri = s\n",
    "        channel_decomp = nn.Conv2d(s.shape[1], t.shape[1], kernel_size=1)\n",
    "        s = channel_decomp(s)\n",
    "        \n",
    "        if s.shape[2] != t.shape[2]:\n",
    "            s = F.interpolate(s, t.size()[-2:], mode='bilinear')\n",
    "                \n",
    "        attn_map = torch.matmul(t, s.transpose(2, 3))\n",
    "        attn_map = F.softmax(attn_map, dim=-1)\n",
    "        guided_s = torch.matmul(attn_map.transpose(2, 3), s)\n",
    "        \n",
    "        channel_comp = nn.Conv2d(guided_s.shape[1], s_pri.shape[1], kernel_size=1)\n",
    "        guided_s = channel_comp(guided_s)\n",
    "        \n",
    "        guided_s = F.interpolate(guided_s, s_pri.size()[-2:], mode='bilinear')\n",
    "        \n",
    "        return guided_s\n",
    "\n",
    "    def s_guided_t(self, t, s):\n",
    "        \"\"\"\n",
    "        Compact Cross-Attention from Student to Teacher feature maps.\n",
    "        \"\"\"\n",
    "        attn_map = torch.matmul(s, t.transpose(2, 3))\n",
    "        attn_map = F.softmax(attn_map, dim=-1)\n",
    "        guided_t = torch.matmul(attn_map.transpose(2, 3), t)\n",
    "        return guided_t\n",
    "    \n",
    "    def forward(self, x, t_attn_skips):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "        \n",
    "        t_e1, t_e2, t_e3, t_e4, t_e5 = t_attn_skips\n",
    "        t_s_e1, t_s_e2, t_s_e3, t_s_e4, t_s_e5 = self.t_guided_s(e1, t_e1), self.t_guided_s(e2, t_e2), self.t_guided_s(e3, t_e3), self.t_guided_s(e4, t_e4), self.t_guided_s(e5, t_e5)\n",
    "        print('----------------------------------------------')\n",
    "        print(e1.shape,e2.shape,e3.shape,e4.shape,e5.shape)\n",
    "        print(t_s_e1.shape, t_s_e2.shape, t_s_e3.shape, t_s_e4.shape, t_s_e5.shape)\n",
    "        d5 = self.Up5(t_s_e5)\n",
    "        d5 = torch.cat((t_s_e4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((t_s_e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((t_s_e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        t_s_e1 = F.interpolate(t_s_e1, size=d2.size()[2:], mode='bilinear', align_corners=True)\n",
    "        d2 = torch.cat((t_s_e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "        out = F.interpolate(out, size=x.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return t_s_e1, t_s_e2, t_s_e3, t_s_e4, t_s_e5, d5, d4, d3, d2, out\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a U-Net with ResNet-18 encoder, 3 input channels, and 4 output channels\n",
    "# model = U_Net_ResNet18(in_ch=3, out_ch=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "db11f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "torch.Size([2, 64, 56, 56]) torch.Size([2, 64, 56, 56]) torch.Size([2, 128, 28, 28]) torch.Size([2, 256, 14, 14]) torch.Size([2, 512, 7, 7])\n",
      "torch.Size([2, 64, 56, 56]) torch.Size([2, 64, 56, 56]) torch.Size([2, 128, 28, 28]) torch.Size([2, 256, 14, 14]) torch.Size([2, 512, 7, 7])\n",
      "torch.Size([2, 64, 112, 112]) torch.Size([2, 64, 56, 56]) torch.Size([2, 128, 28, 28]) torch.Size([2, 256, 14, 14]) torch.Size([2, 512, 7, 7]) torch.Size([2, 256, 14, 14]) torch.Size([2, 128, 28, 28]) torch.Size([2, 64, 56, 56]) torch.Size([2, 32, 112, 112]) torch.Size([2, 4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "r18 = U_Net_ResNet18()\n",
    "x = torch.rand(2,3,224,224)\n",
    "e1,e2,e3,e4,e5, d5,d4,d3,d2,out = r18(x, [e1,e2,e3,e4,e5])\n",
    "print(e1.shape,e2.shape,e3.shape,e4.shape,e5.shape, d5.shape,d4.shape,d3.shape,d2.shape,out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "542690d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class U_Net_MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet with MobileNetV2 Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=4):\n",
    "        super(U_Net_MobileNetV2, self).__init__()\n",
    "\n",
    "        # Encoder (MobileNetV2)\n",
    "        mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "        print(mobilenet_v2)\n",
    "        self.encoder1 = mobilenet_v2.features[0:2]\n",
    "        self.encoder2 = mobilenet_v2.features[2:4]\n",
    "        self.encoder3 = mobilenet_v2.features[4:7]\n",
    "        self.encoder4 = mobilenet_v2.features[7:14]\n",
    "        self.encoder5 = mobilenet_v2.features[14:18]\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.Up5 = up_conv(320, 96)  # MobileNetV2 last layer output has 320 channels\n",
    "        self.Up_conv5 = conv_block(96 + 96, 96)  # Adjust input channels to match MobileNetV2\n",
    "\n",
    "        self.Up4 = up_conv(96, 24)\n",
    "        self.Up_conv4 = conv_block(24 + 32, 24)  # Adjust input channels to match MobileNetV2\n",
    "\n",
    "        self.Up3 = up_conv(24, 16)\n",
    "        self.Up_conv3 = conv_block(16 + 24, 16)  # Adjust input channels to match MobileNetV2\n",
    "\n",
    "        self.Up2 = up_conv(16, 8)\n",
    "        self.Up_conv2 = conv_block(8 + 16, 8)  # Adjust input channels to match MobileNetV2\n",
    "\n",
    "        self.Up1 = up_conv(8, 3)\n",
    "        self.Up_conv1 = conv_block(3 + 3, 3)  # Adjust input channels to match MobileNetV2\n",
    "\n",
    "        self.Conv = nn.Conv2d(3, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def t_guided_s(self, s, t):\n",
    "        \"\"\"\n",
    "        Compact Cross-Attention from Teacher to Student feature maps.\n",
    "        \"\"\"\n",
    "#         print(s.shape)\n",
    "        s_pri = s\n",
    "        channel_decomp = nn.Conv2d(s.shape[1], t.shape[1], kernel_size=1)\n",
    "        s = channel_decomp(s)\n",
    "        \n",
    "        if s.shape[2] != t.shape[2]:\n",
    "            s = F.interpolate(s, t.size()[-2:], mode='bilinear')\n",
    "                \n",
    "        attn_map = torch.matmul(t, s.transpose(2, 3))\n",
    "        attn_map = F.softmax(attn_map, dim=-1)\n",
    "        guided_s = torch.matmul(attn_map.transpose(2, 3), s)\n",
    "        \n",
    "        channel_comp = nn.Conv2d(guided_s.shape[1], s_pri.shape[1], kernel_size=1)\n",
    "        guided_s = channel_comp(guided_s)\n",
    "        \n",
    "        guided_s = F.interpolate(guided_s, s_pri.size()[-2:], mode='bilinear')\n",
    "        \n",
    "        return guided_s\n",
    "    \n",
    "    def forward(self, x, t_attn_skips):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "        \n",
    "        t_e1, t_e2, t_e3, t_e4, t_e5 = t_attn_skips\n",
    "        t_s_e1, t_s_e2, t_s_e3, t_s_e4, t_s_e5 = self.t_guided_s(e1, t_e1), self.t_guided_s(e2, t_e2), self.t_guided_s(e3, t_e3), self.t_guided_s(e4, t_e4), self.t_guided_s(e5, t_e5)\n",
    "        print('----------------------------------------------')\n",
    "        print(e1.shape,e2.shape,e3.shape,e4.shape,e5.shape)\n",
    "        print(t_s_e1.shape, t_s_e2.shape, t_s_e3.shape, t_s_e4.shape, t_s_e5.shape)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        e1 = F.interpolate(e1, size=d2.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Up1(d2)\n",
    "        d1 = torch.cat((x, d1), dim=1)  # Fix the input channel dimension here\n",
    "        d1 = self.Up_conv1(d1)\n",
    "\n",
    "        out = self.Conv(d1)\n",
    "\n",
    "        return e1, e2, e3, e4, e5, d5, d4, d3, d2, out\n",
    "\n",
    "# Helper functions (up_conv and conv_block) should be defined as per your original code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7f4f6255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------\n",
      "torch.Size([2, 16, 112, 112]) torch.Size([2, 24, 56, 56]) torch.Size([2, 32, 28, 28]) torch.Size([2, 96, 14, 14]) torch.Size([2, 320, 7, 7])\n",
      "torch.Size([2, 16, 112, 112]) torch.Size([2, 24, 56, 56]) torch.Size([2, 32, 28, 28]) torch.Size([2, 96, 14, 14]) torch.Size([2, 320, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "r18 = U_Net_MobileNetV2()\n",
    "x = torch.rand(2,3,224,224)\n",
    "e1,e2,e3,e4,e5, d5,d4,d3,d2,out = r18(x, [e1,e2,e3,e4,e5])\n",
    "# print(e1.shape,e2.shape,e3.shape,e4.shape,e5.shape, d5.shape,d4.shape,d3.shape,d2.shape,out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c43be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def at(x, exp):\n",
    "    \"\"\"\n",
    "    attention value of a feature map\n",
    "    :param x: feature\n",
    "    :return: attention value\n",
    "    \"\"\"\n",
    "    return F.normalize(x.pow(exp).mean(1).view(x.size(0), -1))\n",
    "\n",
    "def t_guided_s(s, t):\n",
    "    \"\"\"\n",
    "    Compact Cross-Attention from Teacher to Student feature maps.\n",
    "    \"\"\"\n",
    "    channel_decomp = nn.Conv2d(s.shape[1], t.shape[1], kernel_size=1)\n",
    "    s = channel_decomp(s)\n",
    "\n",
    "    attn_map = torch.matmul(t, s.transpose(2, 3))\n",
    "    attn_map = F.softmax(attn_map, dim=-1)\n",
    "    guided_s = torch.matmul(attn_map.transpose(2, 3), s)\n",
    "\n",
    "    channel_comp = nn.Conv2d(guided_s.shape[1], s.shape[1], kernel_size=1)\n",
    "    guided_s = channel_comp(guided_s)\n",
    "    return guided_s\n",
    "def importance_maps_distillation(s, t, exp=4):\n",
    "    \"\"\"\n",
    "    importance_maps_distillation KD loss, based on \"Paying More Attention to Attention:\n",
    "    Improving the Performance of Convolutional Neural Networks via Attention Transfer\"\n",
    "    https://arxiv.org/abs/1612.03928\n",
    "    :param exp: exponent\n",
    "    :param s: student feature maps\n",
    "    :param t: teacher feature maps\n",
    "    :return: imd loss value\n",
    "    \"\"\"\n",
    "    if s.shape[2] != t.shape[2]:\n",
    "        s = F.interpolate(s, t.size()[-2:], mode='bilinear')\n",
    "    print(s.shape, t.shape)\n",
    "    s = t_guided_s(s,t)\n",
    "    return torch.sum((at(s, exp) - at(t, exp)).pow(2), dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "654df17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 28, 28]) torch.Size([2, 128, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "loss_imd = importance_maps_distillation(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6669421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a,b,c = a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf4245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
